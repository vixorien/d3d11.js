<!DOCTYPE html>
<html>
<head>
	<script src="../build/d3d11.js"></script>
	<script src="../build/d3dmath.js"></script>
	<script src="../build/input.js"></script>
</head>
<body style="background-color:#000;">
	<h1 style="color:#fff;">D3D11.js - Texture Test</h1>

	<canvas id="viewport" width="800" height="600"></canvas>

	<script>
		

		class Vertex
		{
			Position;
			UV;
			Normal;
			Tangent;

			constructor(pos, uv, norm, tang = new Vector3(0,0,0))
			{
				this.Position = pos.slice();
				this.UV = uv.slice();
				this.Normal = norm.slice();
				this.Tangent = tang.slice();
			}

			static GetStride()
			{
				return Float32Array.BYTES_PER_ELEMENT * (3 + 2 + 3 + 3);
			}
		}

		async function loadOBJFile(device, url)
		{
			const resp = await fetch(url);
			const fileText = await resp.text();

			let positions = [];
			let normals = [];
			let uvs = [];
			let vertices = [];
			let indices = [];
			
			let lines = fileText.split("\n");
			for (let i = 0; i < lines.length; i++)
			{
				// Trim and verify
				lines[i] = lines[i].trim();
				if (lines[i].length == 0)
					continue;
				
				// Check the type of line
				if (lines[i].charAt(0) == 'v' && lines[i].charAt(1) == 'n')
				{
					// vn x y z
					let normLine = lines[i].split(' ');
					normals.push(new Vector3(
						parseFloat(normLine[1]),
						parseFloat(normLine[2]),
						parseFloat(normLine[3])));
				}
				else if (lines[i].charAt(0) == 'v' && lines[i].charAt(1) == 't')
				{
					// vt u v
					let uvLine = lines[i].split(' ');
					uvs.push(new Vector2(
						parseFloat(uvLine[1]),
						parseFloat(uvLine[2])));
				}
				else if (lines[i].charAt(0) == 'v')
				{
					// v x y z
					let posLine = lines[i].split(' ');
					positions.push(new Vector3(
						parseFloat(posLine[1]),
						parseFloat(posLine[2]),
						parseFloat(posLine[3])));
				}
				else if (lines[i].charAt(0) == 'f')
				{
					// f 1/2/3 1/2/3 1/2/3
					//  - or -
					// f 1/2/3 1/2/3 1/2/3 1/2/3
					let faceLine = lines[i].split(' ');
					
					// Assume at least 3 verts per face
					for (let f = 1; f <= 3; f++)
					{
						let data = faceLine[f].split('/');
						let p = parseInt(data[0]);
						let u = parseInt(data[1]);
						let n = parseInt(data[2]);

						let vert = new Vertex(
							positions[p - 1],
							uvs[u - 1],
							normals[n - 1]);

						// Convert to left handed
						vert.Position.z *= -1.0; // Invert Z pos
						vert.Normal.z *= -1.0; // Invert Z normal
						vert.UV.y = 1.0 - vert.UV.y; // Flip UV

						// Add to array
						vertices.push(vert);
					}

					// Add indices (0, 2, 1)
					let ind = indices.length;
					indices.push(ind + 0);
					indices.push(ind + 2);
					indices.push(ind + 1);

					// A fourth face? (So 5 total elements after split)
					if (faceLine.length == 5)
					{
						let data = faceLine[4].split('/');
						let p = parseInt(data[0]);
						let u = parseInt(data[1]);
						let n = parseInt(data[2]);

						let vert = new Vertex(
							positions[p - 1],
							uvs[u - 1],
							normals[n - 1]);

						// Convert to left handed
						vert.Position.z *= -1.0; // Invert Z pos
						vert.Normal.z *= -1.0; // Invert Z normal
						vert.UV.y = 1.0 - vert.UV.y; // Flip UV

						// Add to array
						vertices.push(vert);

						// Add another whole face (0, 3, 2)
						indices.push(ind + 0);
						indices.push(ind + 3);
						indices.push(ind + 2);
					}
				}
			}

			// Calculate tangents
			for (let i = 0; i < indices.length;)
			{
				// Grab indices and vertices of first triangle
				let i1 = indices[i++];
				let i2 = indices[i++];
				let i3 = indices[i++];
				let v1 = vertices[i1];
				let v2 = vertices[i2];
				let v3 = vertices[i3];

				// Calculate vectors relative to triangle positions
				let x1 = v2.Position.x - v1.Position.x;
				let y1 = v2.Position.y - v1.Position.y;
				let z1 = v2.Position.z - v1.Position.z;

				let x2 = v3.Position.x - v1.Position.x;
				let y2 = v3.Position.y - v1.Position.y;
				let z2 = v3.Position.z - v1.Position.z;

				// Do the same for vectors relative to triangle uv's
				let s1 = v2.UV.x - v1.UV.x;
				let t1 = v2.UV.y - v1.UV.y;

				let s2 = v3.UV.x - v1.UV.x;
				let t2 = v3.UV.y - v1.UV.y;

				// Create vectors for tangent calculation
				let r = 1.0 / (s1 * t2 - s2 * t1);

				let tx = (t2 * x1 - t1 * x2) * r;
				let ty = (t2 * y1 - t1 * y2) * r;
				let tz = (t2 * z1 - t1 * z2) * r;

				// Adjust tangents of each vert of the triangle
				v1.Tangent.x += tx;
				v1.Tangent.y += ty;
				v1.Tangent.z += tz;

				v2.Tangent.x += tx;
				v2.Tangent.y += ty;
				v2.Tangent.z += tz;

				v3.Tangent.x += tx;
				v3.Tangent.y += ty;
				v3.Tangent.z += tz;
			}
			
			// Orthonormalize
			for (let i = 0; i < vertices.length; i++)
			{
				let n = vertices[i].Normal;
				let t = vertices[i].Tangent;

				vertices[i].Tangent = Vector3.Normalize(
					Vector3.Subtract(t, Vector3.Multiply(n, Vector3.Dot(n, t)))
				);
			}
			
			
			// Copy data to float array
			let floatsPerVert = 3 + 2 + 3 + 3;
			let vbData = new Float32Array(vertices.length * floatsPerVert);
			for (let v = 0; v < vertices.length; v++)
			{
				vbData.set(vertices[v].Position, v * floatsPerVert + 0);
				vbData.set(vertices[v].UV, v * floatsPerVert + 3);
				vbData.set(vertices[v].Normal, v * floatsPerVert + 5);
				vbData.set(vertices[v].Tangent, v * floatsPerVert + 8);
			}
			
			// Create vertex buffer
			let ibData = new Int16Array(indices);
			let vbDesc = new D3D11_BUFFER_DESC(
				Vertex.GetStride() * vertices.length,
				D3D11_USAGE_IMMUTABLE,
				D3D11_BIND_VERTEX_BUFFER,
				0, 0, 0);
			let vb = device.CreateBuffer(vbDesc, vbData);

			// Create index buffer
			let ibDesc = new D3D11_BUFFER_DESC(
				Int16Array.BYTES_PER_ELEMENT * indices.length,
				D3D11_USAGE_IMMUTABLE,
				D3D11_BIND_INDEX_BUFFER,
				0, 0, 0);
			let ib = device.CreateBuffer(ibDesc, ibData);
			
			return [vb, ib, indices.length];
		}

		async function loadTexture2D(device, context, url)
		{
			// Fetch and grab the binary data, then turn into an image
			const resp = await fetch(url);
			const imageBlob = await resp.blob();
			const bitmap = await createImageBitmap(imageBlob);

			// Set up the texture
			let desc = new D3D11_TEXTURE2D_DESC(
				bitmap.width,
				bitmap.height,
				0, // 0 means full mip chain
				1,
				DXGI_FORMAT_R8G8B8A8_UNORM,
				new DXGI_SAMPLE_DESC(1, 0),
				D3D11_USAGE_DEFAULT,
				D3D11_BIND_SHADER_RESOURCE | D3D11_BIND_RENDER_TARGET,
				0,
				D3D11_RESOURCE_MISC_GENERATE_MIPS);
			let texture = device.CreateTexture2D(desc, [bitmap]);

			let srv = device.CreateShaderResourceView(texture, null);
			context.GenerateMips(srv);

			// Release the texture resource since the view has it
			texture.Release();
			bitmap.close(); // Release the browser resource, too
			return srv;
		}

		async function loadTextureCube(device, context, faceURLs)
		{
			let faceTextures = [];
			for (let i = 0; i < faceURLs.length; i++)
			{
				// Fetch and grab the binary data, then turn into an image
				const resp = await fetch(faceURLs[i]);
				const imageBlob = await resp.blob();
				const bitmap = await createImageBitmap(imageBlob);
				faceTextures.push(bitmap);
			}

			// Set up the texture cube
			let desc = new D3D11_TEXTURE2D_DESC(
				faceTextures[0].width,
				faceTextures[0].height,
				1, // No mips
				6, // 6 faces (as array elements)
				DXGI_FORMAT_R8G8B8A8_UNORM,
				new DXGI_SAMPLE_DESC(1, 0),
				D3D11_USAGE_DEFAULT,
				D3D11_BIND_SHADER_RESOURCE,
				0,
				D3D11_RESOURCE_MISC_TEXTURECUBE);
			let texture = device.CreateTexture2D(desc, faceTextures);

			let srv = device.CreateShaderResourceView(texture, null);

			// Release the texture
			texture.Release();
			return srv;
		}

		async function main()
		{

			// Shaders
			let hlslVS = `
				struct VSInput
				{
					float3 position;
					float2 uv;
					float3 normal;
					float3 tangent;
				};

				struct VertexToPixel
				{
					float4 position : SV_POSITION;
					float2 uv		: TEXCOORD;
					float3 normal	: NORMAL;
					float3 tangent	: TANGENT;
					float3 worldPos	: POSITION;
				};

				cbuffer vsData : register(b0)
				{
					matrix world;
					matrix view;
					matrix proj;
				}

				VertexToPixel main(VSInput input)
				{
					VertexToPixel output;

					matrix wvp = mul(mul(proj, view), world);
					output.position = mul(wvp, float4(input.position, 1));

					output.worldPos = mul(world, float4(input.position, 1)).xyz;
					output.normal = mul(float3x3(world), input.normal);
					output.tangent = mul(float3x3(world), input.tangent);
					output.uv = input.uv;
					return output;
				}
			`;

			let hlslPS = `
				struct VertexToPixel
				{
					float4 position : SV_POSITION;
					float2 uv		: TEXCOORD;
					float3 normal	: NORMAL;
					float3 tangent	: TANGENT;
					float3 worldPos	: POSITION;
				};

				struct Light
				{
					float type;
					float intensity;
					float range;
					float pad;
					float3 position;	// auto pad
					float3 direction;	// auto pad
					float3 color;		// auto pad
				};

				cbuffer psData : register(b0)
				{
					float3 cameraPos;	// Auto pad
					float3 tint;		// Auto pad

					Light lights[11];
				}

				Texture2D albedoMap		: register(t0);
				Texture2D normalMap		: register(t1);
				Texture2D metalMap		: register(t2);
				Texture2D roughnessMap	: register(t3);
				TextureCube sky			: register(t4);

				SamplerState samp		: register(s0);

				// Range-based attenuation function
				float attenuate(Light light, float3 worldPos)
				{
					// Calculate the distance between the surface and the light
					float dist = distance(light.position, worldPos);

					// Ranged-based attenuation
					float att = saturate(1.0f - (dist * dist / (light.range * light.range)));

					// Soft falloff
					return att * att;
				}


				float DiffusePBR(float3 normal, float3 dirToLight)
				{
					return saturate(dot(normal, dirToLight));
				}

				// Normal Distribution Function: GGX (Trowbridge-Reitz)
				//
				// a - Roughness
				// h - Half vector
				// n - Normal
				// 
				// D(h, n, a) = a^2 / pi * ((n dot h)^2 * (a^2 - 1) + 1)^2
				float D_GGX(float3 n, float3 h, float roughness)
				{
					// Pre-calculations
					float NdotH = saturate(dot(n, h));
					float NdotH2 = NdotH * NdotH;
					float a = roughness * roughness;
					float a2 = max(a * a, 0.000001); // Applied after remap!

					// ((n dot h)^2 * (a^2 - 1) + 1)
					// Can go to zero if roughness is 0 and NdotH is 1
					float denomToSquare = NdotH2 * (a2 - 1.0) + 1.0;

					// Final value
					return a2 / (3.14159 * denomToSquare * denomToSquare);
				}



				// Fresnel term - Schlick approx.
				// 
				// v - View vector
				// h - Half vector
				// f0 - Value when l = n
				//
				// F(v,h,f0) = f0 + (1-f0)(1 - (v dot h))^5
				float3 F_Schlick(float3 v, float3 h, float3 f0)
				{
					// Pre-calculations
					float VdotH = saturate(dot(v, h));

					// Final value
					return f0 + (1.0 - f0) * pow(1.0 - VdotH, 5.0);
				}



				// Geometric Shadowing - Schlick-GGX
				// - k is remapped to a / 2, roughness remapped to (r+1)/2 before squaring!
				//
				// n - Normal
				// v - View vector
				//
				// G_Schlick(n,v,a) = (n dot v) / ((n dot v) * (1 - k) * k)
				//
				// Full G(n,v,l,a) term = G_SchlickGGX(n,v,a) * G_SchlickGGX(n,l,a)
				float G_SchlickGGX(float3 n, float3 v, float roughness)
				{
					// End result of remapping:
					float k = pow(roughness + 1.0, 2.0) / 8.0f;
					float NdotV = saturate(dot(n, v));

					// Final value
					// Note: Numerator should be NdotV (or NdotL depending on parameters).
					// However, these are also in the BRDF's denominator, so they'll cancel!
					// We're leaving them out here AND in the BRDF function as the
					// dot products can get VERY small and cause rounding errors.
					return 1.0 / (NdotV * (1.0 - k) + k);
				}

				// Cook-Torrance Microfacet BRDF (Specular)
				//
				// f(l,v) = D(h)F(v,h)G(l,v,h) / 4(n dot l)(n dot v)
				// - parts of the denominator are canceled out by numerator (see below)
				//
				// D() - Normal Distribution Function - Trowbridge-Reitz (GGX)
				// F() - Fresnel - Schlick approx
				// G() - Geometric Shadowing - Schlick-GGX
				float3 MicrofacetBRDF(float3 n, float3 l, float3 v, float roughness, float3 f0, out float3 F_out)
				{
					// Other vectors
					float3 h = normalize(v + l);

					// Run numerator functions
					float  D = D_GGX(n, h, roughness);
					float3 F = F_Schlick(v, h, f0);
					float  G = G_SchlickGGX(n, v, roughness) * G_SchlickGGX(n, l, roughness);
	
					// Pass F out of the function for diffuse balance
					F_out = F;

					// Final specular formula
					// Note: The denominator SHOULD contain (NdotV)(NdotL), but they'd be
					// canceled out by our G() term.  As such, they have been removed
					// from BOTH places to prevent floating point rounding errors.
					float3 specularResult = (D * F * G) / 4.0;

					// One last non-obvious requirement: According to the rendering equation,
					// specular must have the same NdotL applied as diffuse!  We'll apply
					// that here so that minimal changes are required elsewhere.
					return specularResult * max(dot(n, l), 0.0);
				}


				// Calculates diffuse amount based on energy conservation
				//
				// diffuse   - Diffuse amount
				// F         - Fresnel result from microfacet BRDF
				// metalness - surface metalness amount
				//
				// Metals should have an albedo of (0,0,0)...mostly
				// See slide 65: http://blog.selfshadow.com/publications/s2014-shading-course/hoffman/s2014_pbs_physics_math_slides.pdf
				float3 DiffuseEnergyConserve(float3 diffuse, float3 F, float metalness)
				{
					return diffuse * (1.0 - F) * (1.0 - metalness);
				}

				float3 DirLightPBR(Light light, float3 normal, float3 worldPos, float3 camPos, float roughness, float metalness, float3 surfaceColor, float3 specularColor)
				{
					// Get normalize direction to the light
					float3 toLight = normalize(-light.direction);
					float3 toCam = normalize(camPos - worldPos);

					// Calculate the light amounts
					float diff = DiffusePBR(normal, toLight);
					float3 F;
					float3 spec = MicrofacetBRDF(normal, toLight, toCam, roughness, specularColor, F);
	
					// Calculate diffuse with energy conservation
					// (Reflected light doesn't get diffused)
					float3 balancedDiff = DiffuseEnergyConserve(float3(diff), spec, metalness);

					// Combine amount with 
					return (balancedDiff * surfaceColor + spec) * light.intensity * light.color;
				}

				float3 PointLightPBR(Light light, float3 normal, float3 worldPos, float3 camPos, float roughness, float metalness, float3 surfaceColor, float3 specularColor)
				{
					// Calc light direction
					float3 toLight = normalize(light.position - worldPos);
					float3 toCam = normalize(camPos - worldPos);

					// Calculate the light amounts
					float atten = attenuate(light, worldPos);
					float diff = DiffusePBR(normal, toLight);
					float3 F;
					float3 spec = MicrofacetBRDF(normal, toLight, toCam, roughness, specularColor, F);

					// Calculate diffuse with energy conservation
					// (Reflected light doesn't diffuse)
					float3 balancedDiff = DiffuseEnergyConserve(float3(diff), spec, metalness);

					// Combine
					return (balancedDiff * surfaceColor + spec) * atten * light.intensity * light.color;
				}


				float4 main(VertexToPixel input) : SV_TARGET
				{
					return sky.Sample(samp, input.normal);

					input.normal = normalize(input.normal);
					input.tangent = normalize(input.tangent);

					float3 albedo = albedoMap.Sample(samp, input.uv).rgb;
					float metal = metalMap.Sample(samp, input.uv).r;
					float rough = roughnessMap.Sample(samp, input.uv).r;
					float3 normalFromMap = normalMap.Sample(samp, input.uv).rgb;
					normalFromMap = normalize(normalFromMap * 2.0 - 1.0);

					// Gather the required vectors for converting the normal
					float3 N = input.normal;
					float3 T = normalize(input.tangent - N * dot(input.tangent, N));
					float3 B = cross(T, N);

					// Create the 3x3 matrix to convert from TANGENT-SPACE normals to WORLD-SPACE normals
					float3x3 TBN = float3x3(T, B, N);

					// Adjust the normal from the map and simply use the results
					input.normal = mul(normalFromMap, TBN);

					float3 specColor = lerp(float3(0.04, 0.04, 0.04), albedo.rgb, metal);

					float3 color = float3(0,0,0);
					float3 toCam = normalize(cameraPos - input.worldPos);
					for(int i = 0; i < 11; i++)
					{
						Light l = lights[i];

						if(l.type == 0.0)
						{
							color += DirLightPBR(
								l, 
								input.normal, 
								input.worldPos, 
								cameraPos, 
								rough, 
								metal, 
								albedo, 
								specColor);
						}
						else if(l.type == 1.0)
						{
							color += PointLightPBR(
								l, 
								input.normal, 
								input.worldPos, 
								cameraPos, 
								rough, 
								metal, 
								albedo, 
								specColor);
						}
					}

					return float4(color, 1);
				}
			`;

			let solidHLSLPS = `
				struct VertexToPixel
				{
					float4 position : SV_POSITION;
					float2 uv		: TEXCOORD;
					float3 normal	: NORMAL;
					float3 worldPos	: POSITION;
				};

				cbuffer psData : register(b0)
				{
					float3 color;
				}

				float4 main(VertexToPixel input) : SV_TARGET
				{
					return float4(color, 1);
				}
			`;

			//let skyVS = `
			//	struct VertexToPixel_Sky
			//	{
			//		float4 screenPosition	: SV_POSITION;
			//		float3 sampleDir		: DIRECTION;
			//	};

			//	cbuffer ExternalData : register(b0)
			//	{
			//		matrix view;
			//		matrix projection;
			//	}

			//	VertexToPixel_Sky main(VertexShaderInput input)
			//	{
			//		VertexToPixel_Sky output;

			//		// Zero out the translation
			//		matrix viewNoTranslation = view;
			//		viewNoTranslation._14 = 0;
			//		viewNoTranslation._24 = 0;
			//		viewNoTranslation._34 = 0;

			//		matrix vp = mul(projection, viewNoTranslation);
			//		output.screenPosition = mul(vp, float4(input.localPosition, 1.0f));

			//		// Z = W for a max depth of 1
			//		output.screenPosition.z = output.screenPosition.w;

			//		// Use local pos as sample direction since we're (presumably) a cube
			//		output.sampleDir = input.localPosition;
			//		return output;
			//	}
			//`;

			//let skyPS = `
			//	struct VertexToPixel_Sky
			//	{
			//		float4 screenPosition	: SV_POSITION;
			//		float3 sampleDir		: DIRECTION;
			//	};

			//	TextureCube SkyTexture		: register(t0);
			//	SamplerState BasicSampler	: register(s0);

			//	float4 main(VertexToPixel_Sky input) : SV_TARGET
			//	{
			//		return SkyTexture.Sample(BasicSampler, input.sampleDir);
			//	}
			//`;

			let input = new Input(document);

			// Some quick vars
			let float32Size = Float32Array.BYTES_PER_ELEMENT;

			// Init the API
			let device = D3D11CreateDevice(document.querySelector("#viewport"));
			let context = device.GetImmediateContext();
			let swapChain = DXGICreateSwapChain(device);
			
			let gl = device.GetAdapter();

			// Make an RTV of the back buffer
			let rtv = device.CreateRenderTargetView(swapChain.GetBuffer(), null);

			// Create a depth buffer
			let depthDesc = new D3D11_TEXTURE2D_DESC(
				gl.canvas.width,
				gl.canvas.height,
				1,
				1,
				DXGI_FORMAT_D24_UNORM_S8_UINT,
				new DXGI_SAMPLE_DESC(1, 0),
				D3D11_USAGE_DEFAULT,
				D3D11_BIND_DEPTH_STENCIL,
				0,
				0);
			let depthBuffer = device.CreateTexture2D(depthDesc, null);

			// Default DSV
			let depthDSV = device.CreateDepthStencilView(depthBuffer, null);

			// Set the targets
			context.OMSetRenderTargets([rtv], depthDSV);

			// Attempt to load an image
			let albedoSRV = await loadTexture2D(device, context, "../assets/textures/floor_albedo.png");
			let normalSRV = await loadTexture2D(device, context, "../assets/textures/floor_normals.png");
			let metalSRV =  await loadTexture2D(device, context, "../assets/textures/floor_metal.png");
			let roughSRV =  await loadTexture2D(device, context, "../assets/textures/floor_roughness.png");
			context.PSSetShaderResources(0, [albedoSRV, normalSRV, metalSRV, roughSRV]);


			// Load a cube map
			let skySRV = await loadTextureCube(
				device,
				context,
				[
					"../assets/skies/cloudsblue/right.png",
					"../assets/skies/cloudsblue/left.png",
					"../assets/skies/cloudsblue/up.png",
					"../assets/skies/cloudsblue/down.png",
					"../assets/skies/cloudsblue/front.png",
					"../assets/skies/cloudsblue/back.png"
				]
			);
			context.PSSetShaderResources(4, [skySRV]);

			// Create/release test
			let crateSRV = await loadTexture2D(device, context, "../assets/textures/crate.png");
			crateSRV.Release();
			

			// Create a sampler
			let sampDesc = new D3D11_SAMPLER_DESC(
				D3D11_FILTER_ANISOTROPIC,
				D3D11_TEXTURE_ADDRESS_WRAP,
				D3D11_TEXTURE_ADDRESS_WRAP,
				D3D11_TEXTURE_ADDRESS_WRAP,
				0,
				16,
				0,
				0,
				0,
				D3D11_FLOAT32_MAX);
			let sampler = device.CreateSamplerState(sampDesc);
			context.PSSetSamplers(0, [sampler]);


			// Common for all verts
			let vbStride = Vertex.GetStride();
			let vbOffset = 0;

			// Load an .obj file and set buffers
			let helixBuffs = await loadOBJFile(device, "../assets/meshes/helix.obj");
			let helixVB = helixBuffs[0];
			let helixIB = helixBuffs[1];
			let helixIndexCount = helixBuffs[2];

			let sphereBuffs = await loadOBJFile(device, "../assets/meshes/sphere.obj");
			let sphereVB = sphereBuffs[0];
			let sphereIB = sphereBuffs[1];
			let sphereIndexCount = sphereBuffs[2];

			let cubeBuffs = await loadOBJFile(device, "../assets/meshes/cube.obj");
			let cubeVB = cubeBuffs[0];
			let cubeIB = cubeBuffs[1];
			let cubeIndexCount = cubeBuffs[2];

			// Create constant buffer
			let elementCount = 16 * 3; // 3 matrices
			let vsCBDesc = new D3D11_BUFFER_DESC(
				elementCount * Float32Array.BYTES_PER_ELEMENT,
				D3D11_USAGE_DEFAULT, // Note: This is generally dynamic in C++, but with no Map/Unmap in WebGL, we've got to use UpdateSubresource
				D3D11_BIND_CONSTANT_BUFFER,
				0, 0, 0);
			let vsCB = device.CreateBuffer(vsCBDesc, null);

			
			let aspectRatio = gl.canvas.width / gl.canvas.height;

			// Camera
			let cameraPosition = new Vector3(0, 0, -10);
			let cameraRotation = new Vector2(0, 0);
			let camDir = new Vector3(0, 0, 1);

			// Set up the initial VS CB data
			let wMat = Matrix4x4.RotationY(0);
			let vMat = Matrix4x4.ViewDirectionLH(cameraPosition, camDir, Vector3.UnitY);
			let pMat = Matrix4x4.PerspectiveFovLH(Math.PI / 4.0, aspectRatio, 0.01, 100);

			let vsData = new Float32Array(elementCount);
			vsData.set(wMat, 0);
			vsData.set(vMat, 16);
			vsData.set(pMat, 32);
			context.UpdateSubresource(vsCB, 0, null, vsData, 0, 0);

			// Cbuffer for pixel shader
			let lightCount = 8 + 3; // 8 point, 3 dir
			let lightSizeInFloats = 16;
			let psElementCount = 8 + lightSizeInFloats * lightCount; // Two vectors, and N lights
			let psCBDesc = new D3D11_BUFFER_DESC(
				psElementCount * Float32Array.BYTES_PER_ELEMENT,
				D3D11_USAGE_DEFAULT, // Note: This is generally dynamic in C++, but with no Map/Unmap in WebGL, we've got to use UpdateSubresource
				D3D11_BIND_CONSTANT_BUFFER,
				0, 0, 0);
			let psCB = device.CreateBuffer(psCBDesc, null);

			// Set up initial PS CB data
			let lightColors = [];
			for (let i = 0; i < 8; i++)
			{
				// Pick one to be bright
				let bright = Math.random() * 3;
				let r = bright < 1 ? 1 : Math.random();
				let g = bright >= 1 && bright < 2 ? 1 : Math.random();
				let b = bright >= 2 ? 1 : Math.random();
				lightColors.push([r, g, b]);
			}
			let psData = new Float32Array(psElementCount);
			psData.set(cameraPosition, 0); // Camera pos
			psData.set([1, 1, 1], 4); // Tint
			for (let i = 0; i < 8; i++)
			{
				psData.set(
					[
						1, // type - 0:dir, 1:point
						1, // intensity
						6, // range
						0, // Pad
						Math.random() * 10 - 5, Math.random() * 10 - 5, Math.random() * 10 - 5, 0, // pos + pad
						0, 0, 0, 0, // direction + pad
						lightColors[i][0], lightColors[i][1], lightColors[i][2], 0 //color + pad
					],
					8 + i * 16);
			}

			// Add the three dir lights after point lights
			let dirs = [];
			dirs.push([1, -1, 1]);
			dirs.push([-1, 0, 0]);
			dirs.push([0, 1, -0.5]);
			for (let i = 8; i < 11; i++)
			{
				psData.set(
					[
						0, // type - 0:dir, 1:point
						Math.random() * 0.5 + 0.5, // intensity
						0, // range
						0, // Pad
						0, 0, 0, 0, // pos + pad
						dirs[i - 8][0], dirs[i - 8][1], dirs[i - 8][2], 0, // direction + pad
						1, 1, 1, 0 //color + pad
					],
					8 + i * 16);
			}


			// Cbuffer for solid color
			let solidCBDesc = new D3D11_BUFFER_DESC(
				4 * Float32Array.BYTES_PER_ELEMENT,
				D3D11_USAGE_DEFAULT, // TODO: Dynamic?
				D3D11_BIND_CONSTANT_BUFFER,
				0, 0, 0);
			let solidCB = device.CreateBuffer(solidCBDesc, null);
			let solidData = new Float32Array(4);
			solidData.set([1, 1, 1], 0);
			context.UpdateSubresource(solidCB, 0, null, solidData, 0, 0);
			context.UpdateSubresource(psCB, 0, null, psData, 0, 0);

			// Set constant buffers
			context.VSSetConstantBuffers(0, [vsCB]);
			context.PSSetConstantBuffers(0, [psCB]);

			// Create an input layout
			let inputElements = [];
			inputElements[0] = new D3D11_INPUT_ELEMENT_DESC("POSITION", 0, DXGI_FORMAT_R32G32B32_FLOAT, 0, 0, D3D11_INPUT_PER_VERTEX_DATA, 0);
			inputElements[1] = new D3D11_INPUT_ELEMENT_DESC("TEXCOORD", 0, DXGI_FORMAT_R32G32_FLOAT, 0, 3 * float32Size, D3D11_INPUT_PER_VERTEX_DATA, 0);
			inputElements[2] = new D3D11_INPUT_ELEMENT_DESC("NORMAL", 0, DXGI_FORMAT_R32G32B32_FLOAT, 0, 5 * float32Size, D3D11_INPUT_PER_VERTEX_DATA, 0);
			inputElements[3] = new D3D11_INPUT_ELEMENT_DESC("TANGENT", 0, DXGI_FORMAT_R32G32B32_FLOAT, 0, 8 * float32Size, D3D11_INPUT_PER_VERTEX_DATA, 0);
			let inputLayout = device.CreateInputLayout(inputElements);
			context.IASetInputLayout(inputLayout);

			// Create shaders
			let vs = device.CreateVertexShader(hlslVS);
			let ps = device.CreatePixelShader(hlslPS);
			let solidPS = device.CreatePixelShader(solidHLSLPS);
			context.VSSetShader(vs);
			context.PSSetShader(ps);


			// Ensure we're set for triangles
			context.IASetPrimitiveTopology(D3D11_PRIMITIVE_TOPOLOGY_TRIANGLELIST);


			function frameloop(time)
			{
				// Update
				let speed = 0.2;
				if (input.IsKeyDown(Keys.Shift)) speed *= 5;
				if (input.IsKeyDown(Keys.Ctrl)) speed *= 0.25;

				let cameraMove = new Vector3();
				let anyMove = false;
				if (input.IsKeyDown(Keys.A)) { anyMove = true; cameraMove.x -= speed; }
				if (input.IsKeyDown(Keys.D)) { anyMove = true; cameraMove.x += speed; }
				if (input.IsKeyDown(Keys.W)) { anyMove = true; cameraMove.z += speed; }
				if (input.IsKeyDown(Keys.S)) { anyMove = true; cameraMove.z -= speed; }
				if (input.IsKeyDown(Keys.Space)) { anyMove = true; cameraMove.y += speed; }
				if (input.IsKeyDown(Keys.X)) { anyMove = true; cameraMove.y -= speed; }

				if (input.IsMouseDown(MouseButtons.Left))
				{
					cameraRotation.x += input.GetMouseDeltaY() * 0.001;
					cameraRotation.y += input.GetMouseDeltaX() * 0.001;

					camDir.x = Math.sin(cameraRotation.y);
					camDir.z = Math.cos(cameraRotation.y);

					camDir.y = -Math.sin(cameraRotation.x);
				}

				if(anyMove)
					cameraPosition = Vector3.Add(cameraPosition, Vector3.Rotate(cameraMove, cameraRotation.x, cameraRotation.y, 0));
				
				
				vMat = Matrix4x4.ViewDirectionLH(
					cameraPosition,
					camDir, //new Vector3(0, 0, 1),
					Vector3.UnitY);

				vsData.set(vMat, 16);

				// Clear the frame
				let black = [0,0,0, 1];
				let cornflowerBlue = [0.39, 0.58, 0.93, 1];
				context.ClearRenderTargetView(rtv, black);
				context.ClearDepthStencilView(depthDSV, D3D11_CLEAR_DEPTH, 1.0, 0);

				// Sphere draws
				{
					// Swap to sphere buffers
					context.PSSetShader(solidPS);
					context.PSSetConstantBuffers(0, [solidCB]);
					context.IASetVertexBuffers(0, [sphereVB], [vbStride], [vbOffset]);
					context.IASetIndexBuffer(sphereIB, DXGI_FORMAT_R16_UINT, 0);

					for (let i = 0; i < 8; i++)
					{
						let offset = (i / 4) * Math.PI * 2;
						let s = Math.sin(time * 0.0005 + offset);
						let c = Math.cos(time * 0.0005 + offset);

						let lightPos = [3 * s, i < 4 ? -3 : 3, 3 * c];

						wMat = Matrix4x4.Translation(lightPos[0], lightPos[1], lightPos[2]);
						vsData.set(wMat, 0);
						context.UpdateSubresource(vsCB, 0, null, vsData, 0, 0);

						// Update PS data for later (8 initial, 16 per light, 4 floats deep)
						psData.set(lightPos, 8 + i * 16 + 4);

						// Update data for this draw
						solidData.set(lightColors[i], 0);
						context.UpdateSubresource(solidCB, 0, null, solidData, 0, 0);

						// Draw sphere
						context.DrawIndexed(sphereIndexCount, 0, 0);
					}
				}

				// Helix draw
				{
					//let scale = 3;
					//let vb = helixVB;
					//let ib = helixIB;
					//let count = helixIndexCount;

					let scale = 7;
					let vb = sphereVB;
					let ib = sphereIB;
					let count = sphereIndexCount;

					//let scale = 4.5;
					//let vb = cubeVB;
					//let ib = cubeIB;
					//let count = cubeIndexCount;

					// Update vertex data
					let rot = new Matrix4x4();
					Matrix4x4.FillIdentity(rot);//Matrix4x4.RotationY(time * -0.00025);
					
					let sc = Matrix4x4.ScaleUniform(scale);
					wMat = Matrix4x4.Multiply(sc, rot);
					vsData.set(wMat, 0);
					context.UpdateSubresource(vsCB, 0, null, vsData, 0, 0);

					// Update pixel data (set above while lights are moving)
					psData.set(cameraPosition, 0);
					context.UpdateSubresource(psCB, 0, null, psData, 0, 0);

				

					// Draw
					context.PSSetShader(ps);
					context.PSSetConstantBuffers(0, [psCB]);
					context.IASetVertexBuffers(0, [vb], [vbStride], [vbOffset]);
					context.IASetIndexBuffer(ib, DXGI_FORMAT_R16_UINT, 0);
					context.DrawIndexed(count, 0, 0);
				}

				// Flush the frame
				swapChain.Present();
				context.OMSetRenderTargets([rtv], depthDSV);

				// End of frame work
				window.requestAnimationFrame(frameloop);
				input.EndOfFrame();
			}

			window.requestAnimationFrame(frameloop);

		}


		main();
	</script>
</body>
</html>

